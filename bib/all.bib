Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{ATLASsim1,
abstract = {The simulation software for the ATLAS Experiment at the Large Hadron Collider is being used for large-scale production of events on the LHC Computing Grid. This simulation requires many components, from the generators that simulate particle collisions, through packages simulating the response of the various detectors and triggers. All of these components come together under the ATLAS simulation infrastructure. In this paper, that infrastructure is discussed, including that supporting the detector description, interfacing the event generation, and combining the GEANT4 simulation of the response of the individual detectors. Also described are the tools allowing the software validation, performance testing, and the validation of the simulated output against known physics processes. {\textcopyright} 2010 CERN for the benefit of the ATLAS collaboration.},
archivePrefix = {arXiv},
arxivId = {1005.4568},
author = {{The ATLAS Collaboration}},
doi = {10.1140/epjc/s10052-010-1429-9},
eprint = {1005.4568},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The ATLAS Collaboration - 2010 - The ATLAS Simulation Infrastructure.pdf:pdf},
isbn = {1005201014299},
issn = {14346052},
journal = {Eur. Phys. J. C},
keywords = {Astronomy,Astrophysics and Cosmology,Elementary Particles,Hadrons,Heavy Ions,Measurement Science and Instrumentation,Nuclear Energy,Nuclear Physics,Quantum Field Theories,Quantum Field Theory,String Theory},
month = {sep},
number = {3},
pages = {823--874},
publisher = {Springer},
title = {{The ATLAS Simulation Infrastructure}},
volume = {70},
year = {2010}
}
@article{geant4atlas,
abstract = {The simulation software for the ATLAS Experiment at the Large Hadron Collider is being used for large-scale production of events on the LHC Computing Grid. This simulation requires many components, from the generators that simulate particle collisions, through packages simulating the response of the various detectors and triggers. All of these components come together under the ATLAS simulation infrastructure. In this paper, that infrastructure is discussed, including that supporting the detector description, interfacing the event generation, and combining the GEANT4 simulation of the response of the individual detectors. Also described are the tools allowing the software validation, performance testing, and the validation of the simulated output against known physics processes.},
archivePrefix = {arXiv},
arxivId = {1005.4568},
author = {{The ATLAS Collaboration}},
doi = {10.1140/EPJC/S10052-010-1429-9},
eprint = {1005.4568},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The ATLAS Collaboration - 2010 - The ATLAS Simulation Infrastructure(2).pdf:pdf},
isbn = {1005201014299},
issn = {1434-6052},
journal = {Eur. Phys. J. C 2010 703},
keywords = {Astronomy,Astrophysics and Cosmology,Elementary Particles,Hadrons,Heavy Ions,Measurement Science and Instrumentation,Nuclear Energy,Nuclear Physics,Quantum Field Theories,Quantum Field Theory,String Theory},
month = {sep},
number = {3},
pages = {823--874},
publisher = {Springer},
title = {{The ATLAS Simulation Infrastructure}},
volume = {70},
year = {2010}
}
@article{AZNLOtune,
abstract = {This paper describes a measurement of the Z/$\gamma$* boson transverse momentum spectrum using ATLAS proton-proton collision data at a centre-of-mass energy of (Formula presented) TeV at the LHC. The measurement is performed in the Z/$\gamma$* → e+e− and Z/$\gamma$* → $\mu$+$\mu$− channels, using data corresponding to an integrated luminosity of 4.7 fb−1. Normalized differential cross sections as a function of the Z/$\gamma$* boson transverse momentum are measured for transverse momenta up to 800 GeV. The measurement is performed inclusively for Z/$\gamma$* rapidities up to 2.4, as well as in three rapidity bins. The channel results are combined, compared to perturbative and resummed QCD calculations and used to constrain the parton shower parameters of Monte Carlo generators.},
archivePrefix = {arXiv},
arxivId = {1406.3660},
author = {{The ATLAS Collaboration}},
doi = {10.1007/JHEP09(2014)145/METRICS},
eprint = {1406.3660},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aad et al. - 2014 - Measurement of the Z$\gamma$ boson transverse momentum distribution in pp collisions at √s = 7 TeV with the ATLAS detect.pdf:pdf},
issn = {10298479},
journal = {J. High Energy Phys.},
keywords = {Hadron-Hadron Scattering},
month = {sep},
number = {9},
pages = {1--47},
publisher = {Springer Verlag},
title = {{Measurement of the Z/$\gamma*$ boson transverse momentum distribution in pp collisions at $\sqrt{s}$ = 7 TeV with the ATLAS detector}},
url = {https://link.springer.com/article/10.1007/JHEP09(2014)145},
volume = {2014},
year = {2014}
}
@inproceedings{TMVAguide,
abstract = {The toolkit for multivariate analysis, TMVA, provides a large set of advanced multivariate analysis techniques for signal/background classification. In addition, TMVA now also contains regression analysis, all embedded in a framework capable of handling the preprocessing of the data and the evaluation of the output, thus allowing a simple and convenient use of multivariate techniques. The analysis techniques implemented in TMVA can be invoked easily and the direct comparison of their performance allows the user to choose the most appropriate for a particular data analysis. This article gives an overview of the TMVA package and presents recently developed features. {\textcopyright} 2010 IOP Publishing Ltd.},
archivePrefix = {arXiv},
arxivId = {physics/0703039},
author = {H{\"{o}}cker, A and Speckmayer, P and Stelzer, J and Voss, H.},
booktitle = {J. Phys. Conf. Ser.},
doi = {10.1088/1742-6596/219/3/032057},
eprint = {0703039},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoecker et al. - 2007 - TMVA - Toolkit for Multivariate Data Analysis.pdf:pdf},
issn = {17426596},
keywords = {Dominik Dannheim (CERN,France),Germany) helgevoss@cernch,Helge Voss (MPI f ¨ ur Kernphysik Heidelberg,Israel) orcohen@cernch,Krakow,Krzysztof Danielowski (IFJ and AGH/UJ,Moritz Backes (Geneva University,Or Cohen (CERN,Poland) KrzysztofDanielowski@cernch,Sophie Henrot-Versil{\'{i}} e (LAL Orsay,Switzerland and Technion,Switzerland) DominikDannheim@cernch,Switzerland) moritzbackes@cernch,Switzerland) tancredicarli@cernch,Tancredi Carli (CERN},
month = {mar},
number = {1 PART 3},
primaryClass = {physics},
title = {{The toolkit for multivariate data analysis, TMVA 4}},
url = {https://arxiv.org/abs/physics/0703039v5},
volume = {219},
year = {2010}
}
@article{Sherpa2dot2,
abstract = {SHERPA is a general-purpose Monte Carlo event generator for the simulation of particle collisions in high-energy collider experiments. We summarise essential features and improvements of the SHERPA 2.2 release series, which is heavily used for event generation in the analysis and interpretation of LHC Run 1 and Run 2 data. We highlight a decade of developments towards ever higher precision in the simulation of particle-collision events.},
archivePrefix = {arXiv},
arxivId = {1905.09127},
author = {Bothmann, Enrico and Chahal, Gurpreet Singh and H{\"{o}}che, Stefan and Krause, Johannes and Krauss, Frank and Kuttimalai, Silvan and Liebschner, Sebastian and Napoletano, Davide and Sch{\"{o}}nherr, Marek and Schulz, Holger and Schumann, Steffen and Siegert, Frank},
doi = {10.21468/SCIPOSTPHYS.7.3.034/PDF},
eprint = {1905.09127},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bothmann et al. - 2019 - Event generation with Sherpa 2.2.pdf:pdf},
issn = {25424653},
journal = {SciPost Phys.},
month = {sep},
number = {3},
pages = {034},
publisher = {SciPost Foundation},
title = {{Event generation with Sherpa 2.2}},
volume = {7},
year = {2019}
}
@article{MuonReco2021,
abstract = {This article documents the muon reconstruction and identification efficiency obtained by the ATLAS experiment for 139 $\hbox {fb}^{-1}$ of pp collision data at $\sqrt{s}=13$ TeV collected between 2015 and 2018 during Run 2 of the LHC. The increased instantaneous luminosity delivered by the LHC over this period required a reoptimisation of the criteria for the identification of prompt muons. Improved and newly developed algorithms were deployed to preserve high muon identification efficiency with a low misidentification rate and good momentum resolution. The availability of large samples of $Z\rightarrow \mu \mu $ and $J/\psi \rightarrow \mu \mu $ decays, and the minimisation of systematic uncertainties, allows the efficiencies of criteria for muon identification, primary vertex association, and isolation to be measured with an accuracy at the per-mille level in the bulk of the phase space, and up to the percent level in complex kinematic configurations. Excellent performance is achieved over a range of transverse momenta from 3 GeV to several hundred GeV, and across the full muon detector acceptance of $|\eta |<2.7$ .},
archivePrefix = {arXiv},
arxivId = {2012.00578},
author = {{The ATLAS Collaboration}},
doi = {10.1140/EPJC/S10052-021-09233-2},
eprint = {2012.00578},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The ATLAS Collaboration - 2021 - Muon reconstruction and identification efficiency in ATLAS using the full Run 2 pp collision data set a.pdf:pdf},
issn = {1434-6052},
journal = {Eur. Phys. J. C 2021 817},
keywords = {Astronomy,Astrophysics and Cosmology,Elementary Particles,Hadrons,Heavy Ions,Measurement Science and Instrumentation,Nuclear Energy,Nuclear Physics,Quantum Field Theories,Quantum Field Theory,String Theory},
month = {jul},
number = {7},
pages = {1--44},
publisher = {Springer},
title = {{Muon reconstruction and identification efficiency in ATLAS using the full Run 2 pp collision data set at $\sqrt{s}=13$ TeV}},
url = {https://link.springer.com/article/10.1140/epjc/s10052-021-09233-2},
volume = {81},
year = {2021}
}
@article{herwigpp2dot7,
abstract = {A new release of the Monte Carlo event generator Herwig++ (version 2.7) is now available. This version comes with a number of improvements including: an interface to the Universal FeynRules Output (UFO) format allowing the simulation of a wide range of new-physics models; developments of the Matchbox framework for next-to-leading order (NLO) simulations; better treatment of QCD radiation in heavy particle decays in new-physics models; a new tune of underlying event and colour connection parameters that allows a good simultaneous description of both Tevatron and LHC underlying event data and the effective cross-section parameter for double-parton scattering.},
archivePrefix = {arXiv},
arxivId = {1310.6877},
author = {Bellm, J. and Gieseke, S. and Grellscheid, D. and Papaefstathiou, A. and Platzer, S. and Richardson, P. and Rohr, C. and Schuh, T. and Seymour, M. H. and Siodmok, A. and Wilcock, A. and Zimmermann, B.},
doi = {10.48550/arXiv.1310.6877},
eprint = {1310.6877},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellm et al. - 2013 - Herwig 2.7 Release Note.pdf:pdf},
month = {oct},
title = {{Herwig++ 2.7 Release Note}},
year = {2013}
}
@article{Higgs2012a,
abstract = {A search for the Standard Model Higgs boson in proton-proton collisions with the ATLAS detector at the LHC is presented. The datasets used correspond to integrated luminosities of approximately 4.8 fb -1 collected at s=7 TeV in 2011 and 5.8 fb -1 at s=8 TeV in 2012. Individual searches in the channels H→ZZ (*) →4ℓ, H→$\gamma$$\gamma$ and H→WW (*) →e$\nu$$\mu$$\nu$ in the 8 TeV data are combined with previously published results of searches for H→ZZ (*) , WW (*) , bb- and $\tau$ + $\tau$ - in the 7 TeV data and results from improved analyses of the H→ZZ (*) →4ℓ and H→$\gamma$$\gamma$ channels in the 7 TeV data. Clear evidence for the production of a neutral boson with a measured mass of 126.0±0.4(stat)±0.4(sys)GeV is presented. This observation, which has a significance of 5.9 standard deviations, corresponding to a background fluctuation probability of 1.7×10 -9 , is compatible with the production and decay of the Standard Model Higgs boson. {\textcopyright} 2012 CERN.},
archivePrefix = {arXiv},
arxivId = {1207.7214},
author = {{The ATLAS Collaboration}},
doi = {10.1016/J.PHYSLETB.2012.08.020},
eprint = {1207.7214},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aad et al. - 2012 - Observation of a new particle in the search for the Standard Model Higgs boson with the ATLAS detector at the LHC.pdf:pdf},
issn = {0370-2693},
journal = {Phys. Lett. B},
month = {sep},
number = {1},
pages = {1--29},
publisher = {North-Holland},
title = {{Observation of a new particle in the search for the Standard Model Higgs boson with the ATLAS detector at the LHC}},
volume = {716},
year = {2012}
}
@article{NNPDF2dot3,
abstract = {We present the first determination of parton distributions of the nucleon at NLO and NNLO based on a global data set which includes LHC data: NNPDF2.3. Our data set includes, besides the deep inelastic, Drell-Yan, gauge boson production and jet data already used in previous global PDF determinations, all the relevant LHC data for which experimental systematic uncertainties are currently available: ATLAS and LHCb W and Z rapidity distributions from the 2010 run, CMS W electron asymmetry data from the 2011 run, and ATLAS inclusive jet cross-sections from the 2010 run. We introduce an improved implementation of the FastKernel method which allows us to fit to this extended data set, and also to adopt a more effective minimization methodology. We present the NNPDF2.3 PDF sets, and compare them to the NNPDF2.1 sets to assess the impact of the LHC data. We find that all the LHC data are broadly consistent with each other and with all the older data sets included in the fit. We present predictions for various standard candle cross-sections, and compare them to those obtained previously using NNPDF2.1, and specifically discuss the impact of ATLAS electroweak data on the determination of the strangeness fraction of the proton. We also present collider PDF sets, constructed using only data from HERA, the Tevatron and the LHC, but find that this data set is neither precise nor complete enough for a competitive PDF determination. {\textcopyright} 2012 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {1207.1303},
author = {Ball, Richard D. and Bertone, Valerio and Carrazza, Stefano and Deans, Christopher S. and {Del Debbio}, Luigi and Forte, Stefano and Guffanti, Alberto and Hartland, Nathan P. and Latorre, Jos{\'{e}} I. and Rojo, Juan and Ubiali, Maria},
doi = {10.1016/j.nuclphysb.2012.10.003},
eprint = {1207.1303},
issn = {05503213},
journal = {Nucl. Phys. B},
keywords = {Collider physics,LHC,Parton distributions,QCD},
month = {feb},
number = {2},
pages = {244--289},
publisher = {North-Holland},
title = {{Parton distributions with LHC data}},
volume = {867},
year = {2013}
}
@article{Fletcher1970,
abstract = {An approach to variable metric algorithms has been investigated in which the linear search subproblem no longer becomes necessary. The property of quadratic termination has been replaced by one of monotonic convergence of the eigenvalues of the approximating matrix to the inverse hessian. A convex class of updating formulas which possess this properly has been established, and a strategy has been indicated for choosing a number of the class so as to keep the approximation away from both singularity and unboundedness. A FORTRAN program has been tested extensively with encouraging results.},
author = {Fletcher, R},
doi = {10.1093/comjnl/13.3.317},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/FLETCHER R - 1970 - A new approach to variable metric algorithms.pdf:pdf},
issn = {00104620},
journal = {Comput. J.},
month = {jan},
number = {3},
pages = {317--322},
publisher = {Oxford Academic},
title = {{New approach to variable metric algorithms}},
url = {https://dx.doi.org/10.1093/comjnl/13.3.317},
volume = {13},
year = {1970}
}
@article{Hayes1989,
abstract = {The bootstrap statistical method is applied to the discrepancy in the one-charged-particle decay modes of the tau lepton. This eliminates questions about the correctness of the errors ascribed to the branching-fraction measurements and the use of Gaussian error distributions for systematic errors. The discrepancy is still seen when the results of the bootstrap analysis are combined with other measurements and with deductions from theory. But the bootstrap method assigns less statistical significance to the discrepancy compared to a method using Gaussian error distributions. {\textcopyright} 1989 The American Physical Society.},
author = {Hayes, Kenneth G. and Perl, Martin L. and Efron, Bradley},
doi = {10.1103/PhysRevD.39.274},
issn = {05562821},
journal = {Phys. Rev. D},
month = {jan},
number = {1},
pages = {274--279},
publisher = {American Physical Society},
title = {{Application of the bootstrap statistical method to the tau-decay-mode problem}},
url = {https://journals.aps.org/prd/abstract/10.1103/PhysRevD.39.274},
volume = {39},
year = {1989}
}
@article{ct10,
abstract = {We extract new parton distribution functions (PDFs) of the proton by global analysis of hard scattering data in the general-mass framework of perturbative quantum chromodynamics. Our analysis includes new theoretical developments together with the most recent collider data from deep-inelastic scattering, vector boson production, and single-inclusive jet production. Because of the difficulty in fitting both the D0 Run-II W lepton asymmetry data and some fixed-target DIS data, we present two families of PDFs, CT10 and CT10W, without and with these high-luminosity W lepton asymmetry data included in the global analysis. With both sets of PDFs, we study theoretical predictions and uncertainties for a diverse selection of processes at the Fermilab Tevatron and the CERN Large Hadron Collider. {\textcopyright} 2010 The American Physical Society.},
archivePrefix = {arXiv},
arxivId = {1007.2241},
author = {Lai, Hung Liang and Guzzi, Marco and Huston, Joey and Li, Zhao and Nadolsky, Pavel M. and Pumplin, Jon and Yuan, C. P.},
doi = {10.1103/PhysRevD.82.074024},
eprint = {1007.2241},
issn = {15507998},
journal = {Phys. Rev. D - Part. Fields, Gravit. Cosmol.},
month = {oct},
number = {7},
pages = {074024},
publisher = {American Physical Society},
title = {{New parton distributions for collider physics}},
url = {https://journals.aps.org/prd/abstract/10.1103/PhysRevD.82.074024},
volume = {82},
year = {2010}
}
@article{Cranmer2012,
author = {Cranmer, Kyle and Lewis, George and Moneta, Lorenzo and Shibata, Akira and Verkerke, Wouter},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cranmer et al. - 2012 - HistFactory A tool for creating statistical models for use with RooFit and RooStats.pdf:pdf},
keywords = {LHC,data analysis,probability density function,statistics},
month = {jan},
title = {{HistFactory: A tool for creating statistical models for use with RooFit and RooStats}},
url = {https://cds.cern.ch/record/1456844},
year = {2012}
}
@article{Weisskopf1981,
author = {Weisskopf, Victor F.},
doi = {10.1063/1.2914365},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weisskopf - 1981 - The development of field theory in the last 50 years.pdf:pdf},
issn = {19450699},
journal = {Phys. Today},
month = {nov},
number = {11},
pages = {69--85},
publisher = {AIP Publishing},
title = {{The development of field theory in the last 50 years}},
url = {/physicstoday/article/34/11/69/433286/The-development-of-field-theory-in-the-last-50},
volume = {34},
year = {1981}
}
@techreport{ATLAS-TDR-TDAQ-PhaseII,
address = {Geneva},
author = {{The ATLAS Collaboration}},
booktitle = {ATLAS-TDR-029},
file = {:home/harry/Documents/phd/l1calo/resources/tdaq-phase2-tdr_2017.pdf:pdf},
institution = {CERN},
title = {{Technical Design Report for the Phase-II Upgrade of the ATLAS TDAQ System}},
url = {https://cds.cern.ch/record/2285584},
year = {2017}
}
@book{LHCVol1,
address = {Geneva},
author = {Br{\"{u}}ning, Oliver Sim and Collier, Paul and Lebrun, P and Myers, Stephen and Ostojic, Ranko and Poole, John and Proudlock, Paul},
doi = {10.5170/CERN-2004-003-V-1},
publisher = {CERN},
series = {CERN Yellow Reports: Monographs},
title = {{LHC Design Report Vol. I: The LHC Main Ring}},
url = {http://cds.cern.ch/record/782076},
year = {2004}
}
@misc{Pequenao2008,
author = {Pequenao, Joao},
keywords = {ATLAS,Computer Generated Images,Detectors,Inner Detector,Outreach,Technology,trackers},
month = {mar},
title = {{Computer generated image of the ATLAS inner detector}},
url = {https://cds.cern.ch/record/1095926},
year = {2008}
}
@article{pythia8dot1,
abstract = {The Pythia program is a standard tool for the generation of high-energy collisions, comprising a coherent set of physics models for the evolution from a few-body hard process to a complex multihadronic final state. It contains a library of hard processes and models for initial- and final-state parton showers, multiple parton-parton interactions, beam remnants, string fragmentation and particle decays. It also has a set of utilities and interfaces to external programs. While previous versions were written in Fortran, Pythia 8 represents a complete rewrite in C++. The current release is the first main one after this transition, and does not yet in every respect replace the old code. It does contain some new physics aspects, on the other hand, that should make it an attractive option especially for LHC physics studies. Program summary: Program title: Pythia 8.1. Catalogue identifier: ACTU_v3_0. Program summary URL: http://cpc.cs.qub.ac.uk/summaries/ACTU_v3_0.html. Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland. Licensing provisions: GPL version 2. No. of lines in distributed program, including test data, etc.: 176 981. No. of bytes in distributed program, including test data, etc.: 2 411 876. Distribution format: tar.gz. Programming language: C++. Computer: Commodity PCs. Operating system: Linux; should also work on other systems. RAM: 8 megabytes. Classification: 11.2. Does the new version supersede the previous version?: yes, partly. Nature of problem: High-energy collisions between elementary particles normally give rise to complex final states, with large multiplicities of hadrons, leptons, photons and neutrinos. The relation between these final states and the underlying physics description is not a simple one, for two main reasons. Firstly, we do not even in principle have a complete understanding of the physics. Secondly, any analytical approach is made intractable by the large multiplicities. Solution method: Complete events are generated by Monte Carlo methods. The complexity is mastered by a subdivision of the full problem into a set of simpler separate tasks. All main aspects of the events are simulated, such as hard-process selection, initial- and final-state radiation, beam remnants, fragmentation, decays, and so on. Therefore events should be directly comparable with experimentally observable ones. The programs can be used to extract physics from comparisons with existing data, or to study physics at future experiments. Reasons for new version: Improved and expanded physics models, transition from Fortran to C++. Summary of revisions: New user interface, transverse-momentum-ordered showers, interleaving with multiple interactions, and much more. Restrictions: Depends on the problem studied. Running time: 10-1000 events per second, depending on process studied. References: [1] T. Sj{\"{o}}strand, P. Ed{\'{e}}n, C. Friberg, L. L{\"{o}}nnblad, G. Miu, S. Mrenna, E. Norrbin, Comput. Phys. Comm. 135 (2001) 238. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {0710.3820},
author = {Sj{\"{o}}strand, Torbj{\"{o}}rn and Mrenna, Stephen and Skands, Peter},
doi = {10.1016/j.cpc.2008.01.036},
eprint = {0710.3820},
issn = {00104655},
journal = {Comput. Phys. Commun.},
keywords = {Event generators,Hadronisation,Monte Carlo,Multiparticle production,Multiple interactions,Parton showers},
mendeley-tags = {Monte Carlo},
month = {jun},
number = {11},
pages = {852--867},
publisher = {North-Holland},
title = {{A brief introduction to PYTHIA 8.1}},
volume = {178},
year = {2008}
}
@article{Wilks1938,
abstract = {The object of this note is to point out and discuss a simple transformation of an absolutely continuous k-variate distribution in the uniform distribution on the k-dimensional hypercube.},
author = {Wilks, S. S.},
doi = {10.1214/aoms/1177732360},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilks - 1938 - The Large-Sample Distribution of the Likelihood Ratio for Testing Composite Hypotheses.pdf:pdf},
issn = {0003-4851},
journal = {Ann. Math. Stat.},
month = {mar},
number = {1},
pages = {60--62},
publisher = {Institute of Mathematical Statistics},
title = {{The Large-Sample Distribution of the Likelihood Ratio for Testing Composite Hypotheses}},
url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-9/issue-1/The-Large-Sample-Distribution-of-the-Likelihood-Ratio-for-Testing/10.1214/aoms/1177732360.full https://projecteuclid.org/journals/annals-of-mathematical-statistics/volum},
volume = {9},
year = {1938}
}
@article{Dirac1930,
abstract = {The relativity quantum theory of an electron moving in a given electro­magnetic field, although successful in predicting the spin properties of the electron, yet involves one serious difficulty which shows that some fundamental alteration is necessary before we can regard it as an accurate description of nature. This difficulty is connected with the fact that the wave equation, which is of the form [W/ c + e / c A 0 + $\rho$ 1 ($\sigma$, p + e / c A) + $\rho$ 3 mc ] $\Psi$ = 0, (1) has, in addition to the wanted solutions for which the kinetic energy of the electron is positive, an equal number of unwanted solutions with negative kinetic energy for the electron, which appear to have no physical meaning. Thus if we take the case of a steady electromagnetic field, equation (1) will admit of periodic solutions of the form $\Psi$ = u e - i E t / h , (2) where u is independent of t , representing stationary states, E being the total energy of the state, including the relativity term mc 2 . There will then exist solutions (2) with negative values for E as well as those with positive values ; in fact, if we take a matrix representation of the operators $\rho$ 1 $\sigma$ 1 , $\rho$ 1 $\sigma$ 2 , $\rho$ 1 $\sigma$ 3 , $\rho$ 3 with the matrix elements all real, then the conjugate complex of any solution of (1) will be a solution of the wave equation obtained from (1) by reversal of the sign of the potentials A, and either the original wave function or its con­jugate complex must refer to a negative E.},
author = {Dirac, Paul Adrien Maurice},
doi = {10.1098/rspa.1930.0013},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Irac et al. - 1930 - A theory of electrons and protons.pdf:pdf},
issn = {0950-1207},
journal = {Proc. R. Soc. London. Ser. A, Contain. Pap. a Math. Phys. Character},
month = {jan},
number = {801},
pages = {360--365},
publisher = {The Royal Society London},
title = {{A theory of electrons and protons}},
url = {https://royalsocietypublishing.org/doi/10.1098/rspa.1930.0013},
volume = {126},
year = {1930}
}
@article{madgraph5amc,
abstract = {We discuss the theoretical bases that underpin the automation of the computations of tree-level and next-to-leading order cross sections, of their matching to parton shower simulations, and of the merging of matched samples that differ by light-parton multiplicities. We present a computer program, MadGraph5 aMC@NLO, capable of handling all these computations — parton-level fixed order, shower-matched, merged — in a unified framework whose defining features are flexibility, high level of parallelisation, and human intervention limited to input physics quantities. We demonstrate the potential of the program by presenting selected phenomenological applications relevant to the LHC and to a 1-TeV e + e − collider. While next-to-leading order results are restricted to QCD corrections to SM processes in the first public version, we show that from the user viewpoint no changes have to be expected in the case of corrections due to any given renormalisable Lagrangian, and that the implementation of these are well under way.},
archivePrefix = {arXiv},
arxivId = {1405.0301},
author = {Alwall, J. and Frederix, R. and Frixione, S. and Hirschi, V. and Maltoni, F. and Mattelaer, O. and Shao, H. S. and Stelzer, T. and Torrielli, P. and Zaro, M.},
doi = {10.1007/JHEP07(2014)079},
eprint = {1405.0301},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alwall et al. - 2014 - The automated computation of tree-level and next-to-leading order differential cross sections, and their match(2).pdf:pdf},
issn = {1029-8479},
journal = {J. High Energy Phys. 2014 20147},
keywords = {Classical and Quantum Gravitation,Elementary Particles,Quantum Field Theories,Quantum Field Theory,Quantum Physics,Relativity Theory,String Theory},
month = {jul},
number = {7},
pages = {1--157},
publisher = {Springer},
title = {{The automated computation of tree-level and next-to-leading order differential cross sections, and their matching to parton shower simulations}},
url = {https://link.springer.com/article/10.1007/JHEP07(2014)079},
volume = {2014},
year = {2014}
}
@inproceedings{JetFlavourUncerts2011,
abstract = {The energy response of the ATLAS calorimeter to a jet depends on the observable properties of a jet, including, for example, the momentum spectra and number of charged hadrons. The fragmentation differences between jets initiated by a quark and jets initiated by a gluon lead to a flavor dependence in the jet energy scale. Because the flavor content of samples varies, this difference results in an additional flavor-dependent term in the jet energy scale uncertainty. This uncertainty term is derived for a general sample of jets and can be up to ∼6% in cases where the flavor composition of a sample of events is poorly known. A template-fit method for determining the flavor composition of a sample of jets is presented. The templates, based on jet properties sensitive to the partonic origin of the jet, allow the determination of flavor composition with a precision of about 10%. The flavor-dependent term of the jet energy scale systematic uncertainty is correspondingly reduced.},
author = {{The ATLAS Collaboration}},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The ATLAS Collaboration - 2011 - Light-quark and Gluon Jets in ATLAS Calorimeter Response, Jet Energy Scale Systematics, and Sample Char.pdf:pdf},
month = {mar},
title = {{Light-quark and Gluon Jets in ATLAS: Calorimeter Response, Jet Energy Scale Systematics, and Sample Characterization}},
year = {2011}
}
@book{georgi1999,
author = {Georgi, Howard},
edition = {Second},
publisher = {Perseus Books Publishing},
title = {{Lie Algebras in Particle Physics}},
year = {1999}
}
@book{Weinberg1995,
abstract = {Available for the first time in paperback, The Quantum Theory of Fields is a self-contained, comprehensive, and up-to-date introduction to quantum field theory from Nobel Laureate Steven Weinberg. Volume I introduces the foundations of quantum field theory. The development is fresh and logical throughout, with each step carefully motivated by what has gone before. After a brief historical outline, the book begins with the principles of relativity and quantum mechanics, and the properties of particles that follow. Quantum field theory emerges from this as a natural consequence. The classic calculations of quantum electrodynamics are presented in a thoroughly modern way, showing the use of path integrals and dimensional regularization. It contains much original material, and is peppered with examples and insights drawn from the author's experience as a leader of elementary particle research. Exercises are included at the end of each chapter.},
address = {Cambridge},
author = {Weinberg, Steven},
booktitle = {Science (80-. ).},
edition = {First},
isbn = {0521550017},
issn = {0036-8075},
number = {5231},
pages = {1--609},
pmid = {17821644},
publisher = {Cambridge University Press},
title = {{The Quantum Theory of Fields}},
volume = {1},
year = {1995}
}
@book{IDTDR1,
author = {{The ATLAS Collaboration}},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The ATLAS Collaboration - 1997 - ATLAS inner detector Technical Design Report, 1(2).pdf:pdf},
isbn = {92908310229789290},
keywords = {ATLAS Reports,CERN Document Server,WebSearch},
publisher = {CERN},
title = {{ATLAS inner detector : Technical Design Report, 1}},
url = {http://cds.cern.ch/record/331063},
year = {1997}
}
@article{Higgs2013,
abstract = {A detailed description is reported of the analysis used by the CMS Collaboration in the search for the standard model Higgs boson in pp collisions at the LHC, which led to the observation of a new boson. The data sample corresponds to integrated luminosities up to 5.1 fb−1 at $ \sqrt{s}=7 $ TeV, and up to 5.3 fb−1 at $ \sqrt{s}=8 $ TeV. The results for five Higgs boson decay modes $\gamma$$\gamma$, ZZ, WW, $\tau$$\tau$, and bb, which show a combined local significance of 5 standard deviations near 125 GeV, are reviewed. A fit to the invariant mass of the two high resolution channels, $\gamma$$\gamma$ and ZZ → 4ℓ, gives a mass estimate of 125.3 ± 0.4 (stat.) ± 0.5 (syst.) GeV. The measurements are interpreted in the context of the standard model Lagrangian for the scalar Higgs field interacting with fermions and vector bosons. The measured values of the corresponding couplings are compared to the standard model predictions. The hypothesis of custodial symmetry is tested through the measurement of the ratio of the couplings to the W and Z bosons. All the results are consistent, within their uncertainties, with the expectations for a standard model Higgs boson.},
archivePrefix = {arXiv},
arxivId = {1303.4571},
author = {{The CMS Collaboration}},
doi = {10.1007/JHEP06(2013)081},
eprint = {1303.4571},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chatrchyan et al. - 2013 - Observation of a new boson with mass near 125 GeV in pp collisions at $ sqrt{s}=7 $ and 8 TeV.pdf:pdf},
issn = {1029-8479},
journal = {J. High Energy Phys. 2013 20136},
keywords = {Classical and Quantum Gravitation,Elementary Particles,Quantum Field Theories,Quantum Field Theory,Quantum Physics,Relativity Theory,String Theory},
month = {jun},
number = {6},
pages = {1--127},
publisher = {Springer},
title = {{Observation of a new boson with mass near 125 GeV in pp collisions at $\sqrt{s}=7$ and 8 TeV}},
url = {https://link.springer.com/article/10.1007/JHEP06(2013)081},
volume = {2013},
year = {2013}
}
@article{EGamCalibration2019,
abstract = {This paper presents the electron and photon energy calibration obtained with the ATLAS detector using about 36 fb-1 of LHC proton-proton collision data recorded at s=13 TeV in 2015 and 2016. The different calibration steps applied to the data and the optimization of the reconstruction of electron and photon energies are discussed. The absolute energy scale is set using a large sample of Z boson decays into electron-positron pairs. The systematic uncertainty in the energy scale calibration varies between 0.03% to 0.2% in most of the detector acceptance for electrons with transverse momentum close to 45 GeV . For electrons with transverse momentum of 10 GeV the typical uncertainty is 0.3% to 0.8% and it varies between 0.25% and 1% for photons with transverse momentum around 60 GeV . Validations of the energy calibration with J/$\psi$ → e+e- decays and radiative Z boson decays are also presented.},
archivePrefix = {arXiv},
arxivId = {1812.03848},
author = {{The ATLAS Collaboration}},
doi = {10.1088/1748-0221/14/03/P03017},
eprint = {1812.03848},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aaboud et al. - 2019 - Electron and photon energy calibration with the ATLAS detector using 2015–2016 LHC proton-proton collision data.pdf:pdf},
issn = {1748-0221},
journal = {J. Instrum.},
keywords = {Calorimeter methods,Pattern recognition,Performance of High Energy Physics Detectors,calibration and fitting methods,cluster finding},
month = {mar},
number = {03},
pages = {P03017},
publisher = {IOP Publishing},
title = {{Electron and photon energy calibration with the ATLAS detector using 2015–2016 LHC proton-proton collision data}},
url = {https://iopscience.iop.org/article/10.1088/1748-0221/14/03/P03017 https://iopscience.iop.org/article/10.1088/1748-0221/14/03/P03017/meta},
volume = {14},
year = {2019}
}
@techreport{ATLAS-TDR-TDAQ-PhaseI,
abstract = {The Phase-I upgrade of the ATLAS Trigger and Data Acquisition (TDAQ) system is to allow the ATLAS experiment to efficiently trigger and record data at instantaneous luminosities that are up to three times that of the original LHC design while maintaining trigger thresholds close to those used in the initial run of the LHC.},
author = {{The ATLAS Collaboration}},
booktitle = {ATLAS-TDR-023-2013},
file = {:home/harry/Documents/phd/l1calo/resources/tdaq-phase1-tdr_2013.pdf:pdf},
title = {{Technical Design Report for the Phase-I Upgrade of the ATLAS TDAQ System}},
url = {http://cds.cern.ch/record/1602235/},
year = {2013}
}
@article{ATLASdq2020,
abstract = {The ATLAS detector at the Large Hadron Collider reads out particle collision data from over 100 million electronic channels at a rate of approximately 100 kHz, with a recording rate for physics events of approximately 1 kHz. Before being certified for physics analysis at computer centres worldwide, the data must be scrutinised to ensure they are clean from any hardware or software related issues that may compromise their integrity. Prompt identification of these issues permits fast action to investigate, correct and potentially prevent future such problems that could render the data unusable. This is achieved through the monitoring of detector-level quantities and reconstructed collision event characteristics at key stages of the data processing chain. This paper presents the monitoring and assessment procedures in place at ATLAS during 2015-2018 data-taking. Through the continuous improvement of operational procedures, ATLAS achieved a high data quality efficiency, with 95.6% of the recorded proton-proton collision data collected at s=13 TeV certified for physics analysis.},
archivePrefix = {arXiv},
arxivId = {1911.04632},
author = {{The ATLAS Collaboration}},
doi = {10.1088/1748-0221/15/04/P04003},
eprint = {1911.04632},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The ATLAS Collaboration - 2020 - ATLAS data quality operations and performance for 2015–2018 data-taking.pdf:pdf},
issn = {1748-0221},
journal = {J. Instrum.},
keywords = {Large detector systems for particle and astroparti,Large detector-systems performance},
month = {apr},
number = {04},
publisher = {IOP Publishing},
title = {{ATLAS data quality operations and performance for 2015–2018 data-taking}},
volume = {15},
year = {2020}
}
@article{powhegbox,
abstract = {In this work we illustrate the POWHEG BOX, a general computer code framework for implementing NLO calculations in shower Monte Carlo programs according to the POWHEG method. Aim of this work is to provide an illustration of the needed theoretical ingredients, a view of how the code is organized and a description of what a user should provide in order to use it.},
archivePrefix = {arXiv},
arxivId = {1002.2581},
author = {Alioli, Simone and Nason, Paolo and Oleari, Carlo and Re, Emanuele},
doi = {10.1007/JHEP06(2010)043},
eprint = {1002.2581},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alioli et al. - 2010 - A general framework for implementing NLO calculations in shower Monte Carlo programs The POWHEG BOX(2).pdf:pdf},
issn = {10298479},
journal = {J. High Energy Phys.},
keywords = {Hadronic colliders,NLO computations,QCD},
month = {jun},
number = {6},
pages = {1--58},
publisher = {Springer Verlag},
title = {{A general framework for implementing NLO calculations in shower Monte Carlo programs: The POWHEG BOX}},
url = {https://link.springer.com/article/10.1007/JHEP06(2010)043},
volume = {2010},
year = {2010}
}
@article{Efron1979,
abstract = {This is a survey article concerning recent advances in certain areas of statistical theory, written for a mathematical audience with no background in statistics. The topics are chosen to illustrate a special point: how the advent of the high-speed computer has affected the development of statistical theory. The topics discussed include nonparametric methods, the jackknife, the bootstrap, cross-validation, error-rate estimation in discriminant analysis, robust estimation, the influence function, censored data, the EM algorithm, and Cox's likelihood function. The exposition is mainly by example, with only a little offered in the way of theoretical development.},
author = {Efron, Bradley},
doi = {10.1137/1021092},
issn = {0036-1445},
journal = {SIAM Rev.},
month = {oct},
number = {4},
pages = {460--480},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Computers and the Theory of Statistics: Thinking the Unthinkable}},
url = {https://epubs.siam.org/doi/10.1137/1021092},
volume = {21},
year = {1979}
}
@article{JESUncerts2017,
abstract = {Jet energy scale measurements and their systematic uncertainties are reported for jets measured with the ATLAS detector using proton-proton collision data with a center-of-mass energy of ffiffi ffi s p ¼ 13 TeV, corresponding to an integrated luminosity of 3.2 fb −1 collected during 2015 at the LHC. Jets are reconstructed from energy deposits forming topological clusters of calorimeter cells, using the anti-k t algorithm with radius parameter R ¼ 0.4. Jets are calibrated with a series of simulation-based corrections and in situ techniques. In situ techniques exploit the transverse momentum balance between a jet and a reference object such as a photon, Z boson, or multijet system for jets with 20 0.8) is derived from dijet p T balance measurements. For jets of p T ¼ 80 GeV, the additional uncertainty for the forward jet calibration reaches its largest value of about 2% in the range j$\eta$j > 3.5 and in a narrow slice of 2.2},
author = {{The ATLAS Collaboration}},
doi = {10.1103/PhysRevD.96.072002},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The ATLAS Collaboration - 2017 - Jet energy scale measurements and their systematic uncertainties in proton-proton collisions at $sqrt{s.pdf:pdf}},
title = {{Jet energy scale measurements and their systematic uncertainties in proton-proton collisions at $\sqrt{s} = 13$ TeV with the ATLAS detector}},
year = {2017}
}
@article{Massey1951,
abstract = {The test is based on the maximum difference between an empirical and a hypothetical cumulative distribution. Percentage points are tabled, and a lower bound to the power function is charted. Confidence limits for a cumulative distribution are described. Examples are given. Indications that the test is superior to the chi-square test are cited.},
author = {Massey, Frank J.},
doi = {10.2307/2280095},
issn = {01621459},
journal = {J. Am. Stat. Assoc.},
month = {mar},
number = {253},
pages = {68},
publisher = {JSTOR},
title = {{The Kolmogorov-Smirnov Test for Goodness of Fit}},
volume = {46},
year = {1951}
}
@article{Yang1954,
abstract = {It is pointed out that the usual principle of invariance under isotopic spin rotation is not consistant with the concept of localized fields. The possibility is explored of having invariance under local isotopic spin rotations. This leads to formulating a principle of isotopic gauge invariance and the existence of a b field which has the same relation to the isotopic spin that the electromagnetic field has to the electric charge. The b field satisfies nonlinear differential equations. The quanta of the b field are particles with spin unity, isotopic spin unity, and electric charge e or zero. {\textcopyright} 1954 The American Physical Society.},
author = {Yang, C. N. and Mills, R. L.},
doi = {10.1103/PhysRev.96.191},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Mills - 1954 - Conservation of Isotopic Spin and Isotopic Gauge Invariance.pdf:pdf},
issn = {0031899X},
journal = {Phys. Rev.},
month = {oct},
number = {1},
pages = {191--195},
publisher = {American Physical Society},
title = {{Conservation of isotopic spin and isotopic gauge invariance}},
url = {https://journals.aps.org/pr/abstract/10.1103/PhysRev.96.191},
volume = {96},
year = {1954}
}
@inproceedings{PhotonIDIsoEff2016,
abstract = {This document summarizes the method to identify isolated photons in the ATLAS experiment , and the techniques to measure the photon identification efficiencies. The strategy developed during LHC Run-I is repeated on the proton-proton collisions collected during 2015 at √ s = 13 TeV, with an integrated luminosity of 3.2 fb −1. Three independent analyses have been exploited. One uses photons from radiative Z → $\gamma$ decays. The second extracts the shower shape properties of electrons from Z → ee decays and extrapolates them to photons. The third directly measures the efficiency on samples of reconstructed photons, after determining and subtracting the hadronic background with a technique based on track isolation. The results from all analyses are then compared with each other and with the prediction from the simulation.},
author = {{The ATLAS Collaboration}},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The ATLAS Collaboration - 2016 - Photon identification in 2015 ATLAS data.pdf:pdf},
keywords = {EGAMMA,photon efficiency,photon identification,photonID},
month = {aug},
title = {{Photon identification in 2015 ATLAS data}},
url = {https://cds.cern.ch/record/2203125},
year = {2016}
}
@article{VBSZy-CONF,
abstract = {test},
archivePrefix = {arXiv},
arxivId = {2305.19142},
author = {{The ATLAS Collaboration}},
eprint = {2305.19142},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The ATLAS Collaboration - 2021 - Measurement of the cross-section of the electroweak production of a $Z gamma$ pair in association with.pdf:pdf},
keywords = {ATLAS Notes,CERN Document Server,WebSearch},
month = {jul},
title = {{Measurement of the cross-sections of the electroweak and total production of a $Z \gamma$ pair in association with two jets in $pp$ collisions at $\sqrt{s}$ = 13 TeV with the ATLAS detector}},
url = {http://cds.cern.ch/record/2779171 http://arxiv.org/abs/2305.19142},
year = {2023}
}
@article{A3tune,
abstract = {A tune of the PPPPPP 8 event generator suitable for inclusive QCD modelling is presented. The A3 tune uses the early Run 2 charged particle distribution and inelastic cross section results from ATLAS in addition to the Run 1 data used previously to construct minimum-bias tunes. For the first time in ATLAS, the tuning considers diffraction modelling parameters and a diffractive model other than the PPPPPP 8 default is used. This results in a better description of the measured inelastic cross-sections and a level of agreement that is comparable to the previous A2 tune for the other distributions considered. This can lead to improved modelling of additional proton-proton collisions in simulation.},
author = {{The ATLAS Collaboration}},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The ATLAS Collaboration - 2016 - The Pythia 8 A3 tune description of ATLAS minimum bias and inelastic measurements incorporating the Don.pdf:pdf},
journal = {ATL-PHYS-PUB-2016-017},
keywords = {MCGENERATORS,Minimum Bias,Pythia8,Tune},
month = {aug},
title = {{The Pythia8 A3 tune description of ATLAS minimum bias and inelastic measurements incorporating the Donnachie-Landshoff diffractive model}},
url = {https://cds.cern.ch/record/2206965 https://inspirehep.net/record/1477266},
year = {2016}
}
@article{geant4,
abstract = {GEANT4 is a toolkit for simulating the passage of particles through matter. It includes a complete range of functionality including tracking, geometry, physics models and hits. The physics processes offered cover a comprehensive range, including electromagnetic, hadronic and optical processes, a large set of long-lived particles, materials and elements, over a wide energy range starting, in some cases, from 250 eV and extending in others to the TeV energy range. It has been designed and constructed to expose the physics models utilised, to handle complex geometries, and to enable its easy adaptation for optimal use in different sets of applications. The toolkit is the result of a worldwide collaboration of physicists and software engineers. It has been created exploiting software engineering and object-oriented technology and implemented in the C++ programming language. It has been used in applications in particle physics, nuclear physics, accelerator design, space engineering and medical physics. {\textcopyright} 2003 Elsevier Science B.V. All rights reserved.},
author = {Agostinelli, S. and Allison, J. and Amako, K. and Apostolakis, J. and Araujo, H. and Arce, P. and Asai, M. and Axen, D. and Banerjee, S. and Barrand, G. and Behner, F. and Bellagamba, L. and Boudreau, J. and Broglia, L. and Brunengo, A. and Burkhardt, H. and Chauvie, S. and Chuma, J. and Chytracek, R. and Cooperman, G. and Cosmo, G. and Degtyarenko, P. and Dell'Acqua, A. and Depaola, G. and Dietrich, D. and Enami, R. and Feliciello, A. and Ferguson, C. and Fesefeldt, H. and Folger, G. and Foppiano, F. and Forti, A. and Garelli, S. and Giani, S. and Giannitrapani, R. and Gibin, D. and {Gomez Cadenas}, J. J. and Gonzalez, I. and {Gracia Abril}, G. and Greeniaus, G. and Greiner, W. and Grichine, V. and Grossheim, A. and Guatelli, S. and Gumplinger, P. and Hamatsu, R. and Hashimoto, K. and Hasui, H. and Heikkinen, A. and Howard, A. and Ivanchenko, V. and Johnson, A. and Jones, F. W. and Kallenbach, J. and Kanaya, N. and Kawabata, M. and Kawabata, Y. and Kawaguti, M. and Kelner, S. and Kent, P. and Kimura, A. and Kodama, T. and Kokoulin, R. and Kossov, M. and Kurashige, H. and Lamanna, E. and Lampen, T. and Lara, V. and Lefebure, V. and Lei, F. and Liendl, M. and Lockman, W. and Longo, F. and Magni, S. and Maire, M. and Medernach, E. and Minamimoto, K. and {Mora de Freitas}, P. and Morita, Y. and Murakami, K. and Nagamatu, M. and Nartallo, R. and Nieminen, P. and Nishimura, T. and Ohtsubo, K. and Okamura, M. and O'Neale, S. and Oohata, Y. and Paech, K. and Perl, J. and Pfeiffer, A. and Pia, M. G. and Ranjard, F. and Rybin, A. and Sadilov, S. and di Salvo, E. and Santin, G. and Sasaki, T. and Savvas, N. and Sawada, Y. and Scherer, S. and Sei, S. and Sirotenko, V. and Smith, D. and Starkov, N. and Stoecker, H. and Sulkimo, J. and Takahata, M. and Tanaka, S. and Tcherniaev, E. and {Safai Tehrani}, E. and Tropeano, M. and Truscott, P. and Uno, H. and Urban, L. and Urban, P. and Verderi, M. and Walkden, A. and Wander, W. and Weber, H. and Wellisch, J. P. and Wenaus, T. and Williams, D. C. and Wright, D. and Yamada, T. and Yoshida, H. and Zschiesche, D.},
doi = {10.1016/S0168-9002(03)01368-8},
issn = {0168-9002},
journal = {Nucl. Instruments Methods Phys. Res. Sect. A Accel. Spectrometers, Detect. Assoc. Equip.},
keywords = {Distributed software development,Geometrical modelling,Object-oriented technology,Particle interactions,Simulation,Software engineering},
month = {jul},
number = {3},
pages = {250--303},
publisher = {North-Holland},
title = {{Geant4—a simulation toolkit}},
volume = {506},
year = {2003}
}
@book{Thomson2013,
address = {Cambridge},
author = {Thomson, Mark},
edition = {First},
isbn = {9781107034266},
publisher = {Cambridge University Press},
title = {{Modern Particle Physics}},
year = {2013}
}
@article{Efron1987,
abstract = {We consider the problem of setting approximate confidence intervals for a single parameter $\theta$ in a multiparameter family. The standard approximate intervals based on maximum likelihood theory, $\theta$̂ ± $\sigma$̂z($\alpha$), can be quite misleading. In practice, tricks based on transformations, bias corrections, and so forth, are often used to improve their accuracy. The bootstrap confidence intervals discussed in this article automatically incorporate such tricks without requiring the statistician to think them through for each new application, at the price of a considerable increase in computational effort. The new intervals incorporate an improvement over previously suggested methods, which results in second-order correctness in a wide variety of problems. In addition to parametric families, bootstrap intervals are also developed for nonparametric situations.},
author = {Efron, Bradley},
doi = {10.2307/2289144},
issn = {01621459},
journal = {J. Am. Stat. Assoc.},
month = {mar},
number = {397},
pages = {171},
publisher = {JSTOR},
title = {{Better Bootstrap Confidence Intervals}},
volume = {82},
year = {1987}
}
@misc{Minuit2,
author = {James, Fred and Winkler, Matthias},
title = {{Minuit2}},
url = {https://root.cern.ch/root/htmldoc/guides/minuit2/Minuit2.html},
year = {2004}
}
@article{ATLASlumi2019,
author = {{The ATLAS Collaboration}},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2019 - Luminosity determination in $pp$ collisions at $sqrt{s}=13$ TeV using the ATLAS detector at the LHC.pdf:pdf},
keywords = {ATLAS,BCM,LUCID,cross-section,luminosity,van der Meer},
month = {jun},
title = {{Luminosity determination in $pp$ collisions at $\sqrt{s}=13$ TeV using the ATLAS detector at the LHC}},
url = {https://cds.cern.ch/record/2677054},
year = {2019}
}
@book{IDTDR2,
author = {Rossi, L and Haywood, S and Romaniouk, A and Nickerson, R},
isbn = {92908310309789290},
keywords = {ATLAS Reports,CERN Document Server,WebSearch},
publisher = {CERN},
title = {{ATLAS inner detector : Technical Design Report, 2}},
url = {http://cds.cern.ch/record/331064},
year = {1997}
}
@article{Efron1988,
abstract = {This is a survey of modern developments in statistical regression, written for the mathematically educated nonstatistician. It begins with a review of the traditional theory of least-squares curve-fitting. Modern developments in regression theory have developed in response to the practical limitations of the least-squares approach. Recent progress has been made feasible by the electronic computer, which frees statisticians from the confines of mathematical tractability. Topics discussed include robust regression, bootstrap measures of variability, local smoothing and cross-validation, projection pursuit, Mallows' Cp criterion, Stein estimation, generalized regression for Poisson data, and regression methods for censored data. All of the methods are illustrated with real-life examples.},
author = {Efron, Bradley},
doi = {10.1137/1030093},
issn = {00361445},
journal = {SIAM Rev.},
keywords = {62-02,62505,Poisson regression,Stein estimation,bootstrap,cross-validation Mallows' Cp,least absolute deviations,projection pursuit,robust regression},
month = {jul},
number = {3},
pages = {421--449},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Computer-intensive methods in statistical regression}},
url = {https://epubs.siam.org/doi/10.1137/1030093},
volume = {30},
year = {1988}
}
@article{pythia8dot2,
abstract = {The Pythia program is a standard tool for the generation of events in high-energy collisions, comprising a coherent set of physics models for the evolution from a few-body hard process to a complex multiparticle final state. It contains a library of hard processes, models for initial-and final-state parton showers, matching and merging methods between hard processes and parton showers, multiparton interactions, beam remnants, string fragmentation and particle decays. It also has a set of utilities and several interfaces to external programs. Pythia 8.2 is the second main release after the complete rewrite from Fortran to C++, and now has reached such a maturity that it offers a complete replacement for most applications, notably for LHC physics studies. The many new features should allow an improved description of data.},
archivePrefix = {arXiv},
arxivId = {1410.3012},
author = {Sj{\"{o}}strand, Torbj{\"{o}}rn and Ask, Stefan and Christiansen, Jesper R. and Corke, Richard and Desai, Nishita and Ilten, Philip and Mrenna, Stephen and Prestel, Stefan and Rasmussen, Christine O. and Skands, Peter Z.},
doi = {10.1016/J.CPC.2015.01.024},
eprint = {1410.3012},
issn = {0010-4655},
journal = {Comput. Phys. Commun.},
keywords = {Event generators,Hadronisation,Matching and merging,Matrix elements,Multiparticle production,Multiparton interactions,Parton showers},
month = {jun},
number = {1},
pages = {159--177},
publisher = {North-Holland},
title = {{An introduction to PYTHIA 8.2}},
volume = {191},
year = {2015}
}
@article{Higgs2012b,
abstract = {Results are presented from searches for the standard model Higgs boson in proton-proton collisions at s=7 and 8 TeV in the Compact Muon Solenoid experiment at the LHC, using data samples corresponding to integrated luminosities of up to 5.1 fb-1 at 7 TeV and 5.3 fb-1 at 8 TeV. The search is performed in five decay modes: $\gamma$$\gamma$, ZZ, W+W-, $\tau$+$\tau$-, and bb-. An excess of events is observed above the expected background, with a local significance of 5.0 standard deviations, at a mass near 125 GeV, signalling the production of a new particle. The expected significance for a standard model Higgs boson of that mass is 5.8 standard deviations. The excess is most significant in the two decay modes with the best mass resolution, $\gamma$$\gamma$ and ZZ; a fit to these signals gives a mass of 125.3±0.4(stat.)±0.5(syst.) GeV. The decay to two photons indicates that the new particle is a boson with spin different from one. {\textcopyright} 2012 CERN.},
archivePrefix = {arXiv},
arxivId = {1207.7235},
author = {{The CMS Collaboration}},
doi = {10.1016/J.PHYSLETB.2012.08.021},
eprint = {1207.7235},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chatrchyan et al. - 2012 - Observation of a new boson at a mass of 125 GeV with the CMS experiment at the LHC.pdf:pdf},
issn = {0370-2693},
journal = {Phys. Lett. B},
keywords = {CMS,Higgs,Physics},
month = {sep},
number = {1},
pages = {30--61},
publisher = {North-Holland},
title = {{Observation of a new boson at a mass of 125 GeV with the CMS experiment at the LHC}},
volume = {716},
year = {2012}
}
@article{Aaboud2017a,
abstract = {This paper describes the implementation and performance of a particle flow algorithm applied to 20.2 fb$$^{-1}$$of ATLAS data from 8 TeV proton–proton collisions in Run 1 of the LHC. The algorithm removes calorimeter energy deposits due to charged hadrons from consideration during jet reconstruction, instead using measurements of their momenta from the inner tracker. This improves the accuracy of the charged-hadron measurement, while retaining the calorimeter measurements of neutral-particle energies. The paper places emphasis on how this is achieved, while minimising double-counting of charged-hadron signals between the inner tracker and calorimeter. The performance of particle flow jets, formed from the ensemble of signals from the calorimeter and the inner tracker, is compared to that of jets reconstructed from calorimeter energy deposits alone, demonstrating improvements in resolution and pile-up stability.},
author = {{The ATLAS Collaboration}},
doi = {10.1140/epjc/s10052-017-5031-2},
issn = {1434-6052},
journal = {Eur. Phys. J. C},
number = {7},
pages = {466},
title = {{Jet reconstruction and performance using particle flow with the ATLAS Detector}},
url = {https://doi.org/10.1140/epjc/s10052-017-5031-2},
volume = {77},
year = {2017}
}
@article{herwigpp,
abstract = {In this paper we describe $\mathsf{Herwig++}$ version 2.2, a general-purpose Monte Carlo event generator for the simulation of hard lepton-lepton and hadron-hadron collisions. A number of important hard scattering processes are available, together with an interface via the Les Houches Accord to specialized matrix element generators for additional processes. The simulation of Beyond the Standard Model (BSM) physics includes a range of models and allows new models to be added by encoding the Feynman rules of the model. The parton-shower approach is used to simulate initial- and final-state QCD radiation, including colour coherence effects, with special emphasis on the correct description of radiation from heavy particles. The underlying event is simulated using an eikonal multiple parton-parton scattering model. The formation of hadrons from the quarks and gluons produced in the parton shower is described using the cluster hadronization model. Hadron decays are simulated using matrix elements, where possible including spin correlations and off-shell effects.},
archivePrefix = {arXiv},
arxivId = {0803.0883},
author = {B{\"{a}}hr, Manuel and Gieseke, Stefan and Gigg, Martyn A. and Grellscheid, David and Hamilton, Keith and Latunde-Dada, Oluseyi and Pl{\"{a}}tzer, Simon and Richardson, Peter and Seymour, Michael H. and Sherstnev, Alexander and Webber, Bryan R.},
doi = {10.1140/EPJC/S10052-008-0798-9},
eprint = {0803.0883},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/B{\"{a}}hr et al. - 2008 - Herwig physics and manual.pdf:pdf},
issn = {1434-6052},
journal = {Eur. Phys. J. C 2008 584},
keywords = {Astronomy,Astrophysics and Cosmology,Elementary Particles,Hadrons,Heavy Ions,Measurement Science and Instrumentation,Nuclear Energy,Nuclear Physics,Quantum Field Theories,Quantum Field Theory,String Theory},
month = {nov},
number = {4},
pages = {639--707},
publisher = {Springer},
title = {{Herwig++ physics and manual}},
volume = {58},
year = {2008}
}
@article{Assmann2002,
abstract = {The Large Electron Positron collider LEP at CERN was commissioned in 1989 and finished operation in November 2000. During this period it was operated in different modes, with different optics, at different energies, and with varied performance. In the end, LEP surpassed all relevant design parameters. It has provided a large amount of data for the precision study of the standard model, first on the Z0 resonance, and then above the W± pair threshold. Finally, with beam energies above 100 GeV, a tantalizing glimpse of what might have been the Higgs boson was observed. A brief history of the main modes of operation, associated performance, the highlights and the challenges met over the 12 years of running is presented.},
author = {Assmann, Ralph and Lamont, Mike and Myers, Steve},
doi = {10.1016/S0920-5632(02)90005-8},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Assmann, Lamont, Myers - 2002 - A Brief History of the LEP Collider.pdf:pdf},
issn = {09205632},
journal = {Nucl. Phys. B, Proc. Suppl.},
keywords = {CERN Document Server,WebSearch,accelerator,accelerators,beam,beams,calibration,dynamics,electromagnets,electron,history,magnets,particle,reviews,rings,storage,synchrotrons},
month = {apr},
number = {2-3},
pages = {17--31},
publisher = {Elsevier BV},
title = {{A Brief History of the LEP Collider}},
url = {https://cds.cern.ch/record/549223},
volume = {109},
year = {2002}
}
@article{Achenbach2008,
abstract = {The ATLAS Level-1 Calorimeter Trigger uses reduced-granularity information from all the ATLAS calorimeters to search for high transverse-energy electrons, photons, $\tau$ leptons and jets, as well as high missing and total transverse energy. The calorimeter trigger electronics has a fixed latency of about 1 $\mu$s, using programmable custom-built digital electronics. This paper describes the Calorimeter Trigger hardware, as installed in the ATLAS electronics cavern. {\textcopyright} 2008 IOP Publishing Ltd and SISSA.},
author = {Achenbach, R. and Adragna, P. and Andrei, V. and Apostologlou, P. and {\AA}sman, B. and Ay, C. and Barnett, B. M. and Bauss, B. and Bendel, M. and Bohm, C. and Booth, J. R.A. and Brawn, I. P. and Bright-Thomas, P. and Charlton, D. G. and Collins, N. J. and Curtis, C. J. and Dahlhoff, A. and Davis, A. O. and Eckweiler, S. and Edwards, J. P. and Eisenhandler, E. and Faulkner, P. J.W. and Fleckner, J. and F{\"{o}}hlisch, F. and Garvey, J. and Gee, C. N.P. and Gillman, A. R. and Hanke, P. and Hatley, R. P. and Hellman, S. and Hidv{\'{e}}gi, A. and Hillier, S. J. and Jakobs, K. and Johansen, M. and Kluge, E. E. and Landon, M. and Lendermann, V. and Lilley, J. N. and Mahboubi, K. and Mahout, G. and Mass, A. and Meier, K. and Moa, T. and Moyse, E. and M{\"{u}}ller, F. and Neusiedl, A. and N{\"{o}}ding, C. and Oltmann, B. and Pentney, J. M. and Perera, V. J.O. and Pfeiffer, U. and Prieur, D. P.F. and Qian, W. and Rees, D. L. and Rieke, S. and R{\"{u}}hr, F. and Sankey, D. P.C. and Sch{\"{a}}fer, U. and Schmitt, K. and Schultz-Coulon, H. C. and Schumacher, C. and Silverstein, S. and Staley, R. J. and Stamen, R. and Stockton, M. C. and Tapprogge, S. and Thomas, J. P. and Trefzger, T. and Watkins, P. M. and Watson, A. and Weber, P. and Woehrling, E. E.},
doi = {10.1088/1748-0221/3/03/P03001},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Achenbach et al. - 2008 - The ATLAS Level-1 Calorimeter Trigger.pdf:pdf},
issn = {1748-0221},
journal = {J. Instrum.},
keywords = {Digital electronic circuits,Trigger concepts and systems (hardware and softwar},
month = {mar},
number = {03},
publisher = {IOP Publishing},
title = {{The ATLAS Level-1 Calorimeter Trigger}},
volume = {3},
year = {2008}
}
@incollection{Powell1983,
abstract = {Variable metric methods solve nonlinearly constrained optimization problems, using calculated first derivatives and a single positive definite matrix, which holds second derivative information that is obtained automatically. The theory of these methods is shown by analysing the global and local convergence properties of a basic algorithm, and we find that superlinear convergence requires less second derivative information than in the unconstrained case. Moreover, in order to avoid the difficulties of inconsistent linear approximations to constraints, careful consideration is given to the calculation of search directions by unconstrained minimization subproblems. The Maratos effect and relations to reduced gradient algorithms are studied briefly.},
author = {Powell, M. J. D.},
booktitle = {Math. Program. State Art},
doi = {10.1007/978-3-642-68874-4_12},
isbn = {978-3-642-68874-4},
pages = {288--311},
publisher = {Springer, Berlin, Heidelberg},
title = {{Variable Metric Methods for Constrained Optimization}},
url = {https://link.springer.com/chapter/10.1007/978-3-642-68874-4_12},
year = {1983}
}
@article{PDG2022,
author = {{Particle Data Group}},
doi = {10.1093/ptep/ptac097},
journal = {Prog. Theor. Exp. Phys.},
pages = {083C01},
title = {{Review of Particle Physics -- Quantum Chromodynamics}},
volume = {2022},
year = {2022}
}
@article{Mobs2018,
author = {Mobs, Esma},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mobs - 2018 - The CERN accelerator complex - August 2018.pdf:pdf},
journal = {CERN},
keywords = {Accelerators,LHC,LHC experiments,accelerator},
month = {aug},
title = {{The CERN accelerator complex - August 2018}},
url = {https://cds.cern.ch/record/2636343},
year = {2018}
}
@inproceedings{Deviveiros2019,
author = {Deviveiros, Pier-Olivier},
month = {aug},
publisher = {ATLAS Internal},
title = {{Run 3 L1 algorithm and trigger performance forum}},
url = {https://indico.cern.ch/event/839580/},
year = {2019}
}
@misc{Davidon1959,
abstract = {This is a method for determining numerically local minima of differentiable functions of several variables. In the process of locating each minimum, a matrix which characterizes the behavior of the function about the minimum is determined. For a region in which the function depends quadratically on the variables, no more than N iterations are required, where N is the number of variables. By suitable choice of starting values, and without modification of the procedure, linear constraints can be imposed upon the variables.},
address = {Argonne, IL (United States)},
author = {Davidon, William C.},
booktitle = {SIAM J. Optim.},
doi = {10.1137/0801001},
institution = {Argonne National Laboratory (ANL)},
issn = {10526234},
keywords = {Optimization,Quasi-Newton,Variable metric algorithms},
month = {may},
number = {1},
pages = {1--17},
title = {{Variable metric method for minimization}},
url = {http://www.osti.gov/servlets/purl/4252678-8PdOvt/},
volume = {1},
year = {1991}
}
@book{IBLTDR,
author = {Capeans, M and Flick, T and Vuillermet, R and Darbo, G and Pernegger, H and Einsweiller, K and Garcia-Sciveres, M and Elsing, M and Rohne, O and Gemme, C},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Capeans et al. - 2010 - ATLAS Insertable B-Layer Technical Design Report.pdf:pdf},
keywords = {CERN Document Server,LHCC Public Documents,WebSearch},
month = {sep},
title = {{ATLAS Insertable B-Layer Technical Design Report}},
url = {https://cds.cern.ch/record/1291633},
year = {2010}
}
@article{powheg,
abstract = {The aim of this work is to describe in detail the POWHEG method, first suggested by one of the authors, for interfacing parton-shower generators with NLO QCD computations. We describe the method in its full generality, and then specify its features in two subtraction frameworks for NLO calculations: the Catani-Seymour and the Frixione-Kunszt-Signer approach. Two examples are discussed in detail in both approaches: the production of hadrons in e +e - collisions, and the Drell-Yan vector-boson production in hadronic collisions. {\textcopyright} SISSA 2007.},
archivePrefix = {arXiv},
arxivId = {0709.2092},
author = {Frixione, Stefano and Nason, Paolo and Oleari, Carlo},
doi = {10.1088/1126-6708/2007/11/070},
eprint = {0709.2092},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamilton et al. - 2007 - Matching NLO QCD computations with parton shower simulations the POWHEG method.pdf:pdf},
issn = {11266708},
journal = {J. High Energy Phys.},
keywords = {Hadronic colliders,NLO computations,QCD},
month = {nov},
number = {11},
pages = {070},
publisher = {IOP Publishing},
title = {{Matching NLO QCD computations with parton shower simulations: The POWHEG method}},
url = {https://iopscience.iop.org/article/10.1088/1126-6708/2007/11/070 https://iopscience.iop.org/article/10.1088/1126-6708/2007/11/070/meta},
volume = {2007},
year = {2007}
}
@report{gellmann1961,
author = {Gell-Mann, Murray},
doi = {10.2172/4008239},
institution = {California Institute of Technology},
number = {1},
pages = {361--364},
title = {{The eightfold way: A theory of strong interaction symmetry}},
volume = {8},
year = {1961}
}
@misc{Pequenao2008a,
author = {Pequenao, Joao},
keywords = {ATLAS,Calorimeters,Computer Generated Images,Detectors,Outreach,Technology},
month = {mar},
title = {{Computer Generated image of the ATLAS calorimeter}},
url = {https://cds.cern.ch/record/1095927},
year = {2008}
}
@article{Pauli1925,
abstract = {{Es wird, namentlich im Hinblick auf den $\sim$:illikan-Land$\sim$sehen Befund der Darstellbarkeit der Alkalidubletts durch relativistische Fcrmeln und auf Grund yon in einer fr$\sim$iheren Arbeit erhaltenen Resultaten, die Auffassung vorgeschlagen, dal] in diesen Dubletts und ihrem anomalen Zeemaneffekt eine klassisch nicht be-schreibbare Zweideutigkeit der quantentheoretischen Eigensch$\sim$ten des Leueht-elektrons zum Ausdruck kommt, ohne dai] hierbei die abgeschlossene Edelgas-konfiguration des Atomrestes in Form eines Rumpfimpulses oder als Sitz der magneto-mechanischen Anomalie des Atoms beteiligt ist. Sodann wird versucht, diesen als provisorisehe Arbeitshypothese eingenommenen Standpunkt trotz ihm entgegenstehender prinzipieller Schwierigkeiten auch bei anderen Atomen als den Alkalien in seinen Konsequenzen mhglichst weit zu verfolgen. Dabei zeigt sich zunichst, daft er es im Gegensatz zur iiblichen Auffassung ermhglicht, im Falle eines starken itufleren Magnetfe]des, we yon den Kopplungskr$\sim$ften zwisehen Atom-rest und Leuchte]ektron abgesehen werden kann, diesen beiden Teilsystemen hinsichtlich der Anzahl ihrer station:$\sim$rea Zust$\sim$ade sowie der Werte ihrer Qaanten-zahlen and ihrer magnetischen Energie keine anderen Eigenschaften zuzuschreiben als dem freien Atomrest bzw. dem Leuchtelektron bei den Alkalien. Auf Grand dieses Ergebnisses gelangt man ferner zu einer allgemeinen Klassifikation jedes Etektrons im Atom durch die Flauptquantenzaht n and zwei Nebenquantenzahlen kl und k$\sim$, zu denen bei Anwesetdaeit eines Eulleren Feldes noch eine weitere Quantenzahl m 1 hinzutritt. In Ankniipfung an eine neaere Arbeit yon E. C. S t o n e r fiihrt diese Klassifikation zu einer allgemeinen quaatentheoretischen Formulierung des Absehlusses der Elektronengruppen im Atom. w 1. Die Permanenz der Quantenzahlen (Aufbauprinzip) bei Komplexstruktur und Zeemaneffekt. In einer frfiheren Arbeit') wurde hervorgehoben, dal} die iiblJche u nach der die inneren ab-geschlossenen E]ektronenschalen im Atom in Form yon Rumpfimpulsen and als eigentlicher Sitz der magneto-mechanischen Anomalie an der Komplex-struktur der optischen Spektren und ihrem anomalen Zeemaneffekt wesent-lich beteJlJgt sein so]len, zu verschiedenen ernsfliehen SchwJerigkeiten Anlaf gibt. ]=Iierdurch wird es nahe gelegt, dieser u die andere gegeniiber zu steUen, daft insbesondere die Dublettstruktur der Alkali-spektren sowie $\sim$ anomaler Zeemaneffekt in einer klassisch nichg be-schreibbaren Zweideu$\sim$gkei$\sim$ der quan$\sim$entheoretischen Eigensehaften des Leuchtelektrons seine Ursache hat. Diese Auffassung s$\sim$iitzt sich iiber-1) ZS. f. Phys. 31, 373, 1925. Am Sehlusse dieser Arbeit ist anf die vorliegende Note Bezug genommen. Zr fiir Physik. Bd. XXXI. 51},
author = {Pauli, W.},
doi = {10.1007/BF02980631},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pauli - 1925 - {\"{U}}ber den Zusammenhang des Abschlusses der Elektronengruppen im Atom mit der Komplexstruktur der Spektren.pdf:pdf},
issn = {00443328},
journal = {Zeitschrift f{\"{u}}r Phys.},
keywords = {Beam Physics,Hadrons,Heavy Ions,Nuclear Fusion,Nuclear Physics,Particle Acceleration and Detection},
month = {feb},
number = {1},
pages = {765--783},
publisher = {Springer},
title = {{{\"{U}}ber den Zusammenhang des Abschlusses der Elektronengruppen im Atom mit der Komplexstruktur der Spektren}},
url = {https://link.springer.com/article/10.1007/BF02980631},
volume = {31},
year = {1925}
}
@inproceedings{Brawn2019,
note = {[ATLAS Internal]},
author = {Brawn, Ian},
file = {:home/harry/Documents/phd/l1calo/resources/L1Calo_191022_Overview.pdf:pdf},
month = {oct},
title = {{L1Calo Overview, Status, Installation \& Commissioning}},
url = {https://indico.cern.ch/event/829769/contributions/3572289},
year = {2019}
}
@article{Nason2004,
abstract = {I show that with simple extensions of the shower algorithms in Monte Carlo programs, one can implement NLO corrections to the hardest emission that overcome the problems of negative weighted events found in previous implementations. Simple variants of the same method can be used for an improved treatment of matrix element corrections in Shower Monte Carlo programs. {\textcopyright} SISSA/ISAS 2004.},
archivePrefix = {arXiv},
arxivId = {hep-ph/0409146},
author = {Nason, Paolo},
doi = {10.1088/1126-6708/2004/11/040},
eprint = {0409146},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huss et al. - 2004 - A new method for combining NLO QCD with shower Monte Carlo algorithms.pdf:pdf},
issn = {10298479},
journal = {J. High Energy Phys.},
keywords = {Hadronic Colliders,NLO Computations,Parton Model,QCD},
month = {dec},
number = {11},
pages = {1097--1124},
primaryClass = {hep-ph},
publisher = {IOP Publishing},
title = {{A new method for combining NLO QCD with shower Monte Carlo algorithms}},
url = {https://iopscience.iop.org/article/10.1088/1126-6708/2004/11/040 https://iopscience.iop.org/article/10.1088/1126-6708/2004/11/040/meta},
volume = {8},
year = {2004}
}
@article{Aad2017a,
abstract = {The reconstruction of the signal from hadrons and jets emerging from the proton–proton collisions at the Large Hadron Collider (LHC) and entering the ATLAS calorimeters is based on a three-dimensional topological clustering of individual calorimeter cell signals. The cluster formation follows cell signal-significance patterns generated by electromagnetic and hadronic showers. In this, the clustering algorithm implicitly performs a topological noise suppression by removing cells with insignificant signals which are not in close proximity to cells with significant signals. The resulting topological cell clusters have shape and location information, which is exploited to apply a local energy calibration and corrections depending on the nature of the cluster. Topological cell clustering is established as a well-performing calorimeter signal definition for jet and missing transverse momentum reconstruction in ATLAS.},
author = {{The ATLAS Collaboration}},
doi = {10.1140/epjc/s10052-017-5004-5},
file = {:home/harry/Documents/phd/l1calo/resources/1603.02934.pdf:pdf},
issn = {1434-6052},
journal = {Eur. Phys. J. C},
number = {7},
pages = {490},
title = {{Topological cell clustering in the ATLAS calorimeters and its performance in LHC Run 1}},
url = {https://doi.org/10.1140/epjc/s10052-017-5004-5},
volume = {77},
year = {2017}
}
@article{Thomson2018,
author = {Thomson, Mark},
title = {{Modern Particle Physics -- Errata}},
url = {https://www.hep.phy.cam.ac.uk/$\sim$thomson/MPP/ModernParticlePhysics_Errata.pdf},
year = {2018}
}
@article{Aad2017b,
abstract = {The reconstruction of the signal from hadrons and jets emerging from the proton–proton collisions at the Large Hadron Collider (LHC) and entering the ATLAS calorimeters is based on a three-dimensional topological clustering of individual calorimeter cell signals. The cluster formation follows cell signal-significance patterns generated by electromagnetic and hadronic showers. In this, the clustering algorithm implicitly performs a topological noise suppression by removing cells with insignificant signals which are not in close proximity to cells with significant signals. The resulting topological cell clusters have shape and location information, which is exploited to apply a local energy calibration and corrections depending on the nature of the cluster. Topological cell clustering is established as a well-performing calorimeter signal definition for jet and missing transverse momentum reconstruction in ATLAS.},
author = {{The ATLAS Collaboration}},
doi = {10.1140/epjc/s10052-017-5004-5},
file = {:home/harry/Documents/phd/l1calo/resources/1603.02934.pdf:pdf},
issn = {1434-6052},
journal = {Eur. Phys. J. C},
number = {7},
pages = {490},
title = {{Topological cell clustering in the ATLAS calorimeters and its performance in LHC Run 1}},
url = {https://doi.org/10.1140/epjc/s10052-017-5004-5},
volume = {77},
year = {2017}
}
@article{Collins1977,
abstract = {We give the general form of the angular distribution of lepton pairs produced in hadron collisions, where each dilepton is assumed to come from the decay of a virtual photon. The Drell-Yan model extended to include parton transverse momentum (with on-shell quarks) is then used to calculate the three coefficients in the distribution. {\textcopyright} 1977 The American Physical Society.},
author = {Collins, John C. and Soper, Davison E.},
doi = {10.1103/PhysRevD.16.2219},
issn = {05562821},
journal = {Phys. Rev. D},
month = {oct},
number = {7},
pages = {2219--2225},
publisher = {American Physical Society},
title = {{Angular distribution of dileptons in high-energy hadron collisions}},
url = {https://journals.aps.org/prd/abstract/10.1103/PhysRevD.16.2219},
volume = {16},
year = {1977}
}
@article{Kolmogoroff1933,
abstract = {Contributo allo studio della possibilit{\`{a}} di determinare una legge di distribuzione conoscendo i risultati di un numero finito di prove.},
author = {Kolmogoroff, A},
journal = {G. dell'Istituto Ital. degli Attuari},
pages = {83--91},
title = {{Sulla determinazione empirica di una legge di distribuzione}},
volume = {4},
year = {1933}
}
@article{antikt,
abstract = {The k t and Cambridge/Aachen inclusive jet finding algorithms for hadron-hadron collisions can be seen as belonging to a broader class of sequential recombination jet algorithms, parametrised by the power of the energy scale in the distance measure. We examine some properties of a new member of this class, for which the power is negative. This ''anti-k t'' algorithm essentially behaves like an idealised cone algorithm, in that jets with only soft fragmentation are conical, active and passive areas are equal, the area anomalous dimensions are zero, the non-global logarithms are those of a rigid boundary and the Milan factor is universal. None of these properties hold for existing sequential recombination algorithms, nor for cone algorithms with split-merge steps, such as SISCone. They are however the identifying characteristics of the collinear unsafe plain ''iterative cone'' algorithm, for which the anti-k t algorithm provides a natural, fast, infrared and collinear safe replacement.},
archivePrefix = {arXiv},
arxivId = {0802.1189},
author = {Cacciari, Matteo and Salam, Gavin P and Soyez, Gregory},
doi = {10.1088/1126-6708/2008/04/063},
eprint = {0802.1189},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huss et al. - 2008 - The anti-kt jet clustering algorithm.pdf:pdf},
issn = {1126-6708},
journal = {J. High Energy Phys.},
keywords = {Hadronic colliders,Jets,QCD},
month = {apr},
number = {04},
pages = {063},
publisher = {IOP Publishing},
title = {{The anti-kt jet clustering algorithm}},
url = {https://iopscience.iop.org/article/10.1088/1126-6708/2008/04/063 https://iopscience.iop.org/article/10.1088/1126-6708/2008/04/063/meta},
volume = {2008},
year = {2008}
}
@article{ATLAStrigops2020,
abstract = {The ATLAS experiment at the Large Hadron Collider employs a two-level trigger system to record data at an average rate of 1 kHz from physics collisions, starting from an initial bunch crossing rate of 40 MHz. During the LHC Run 2 (2015–2018), the ATLAS trigger system operated successfully with excellent performance and flexibility by adapting to the various run conditions encountered and has been vital for the ATLAS Run-2 physics programme. For proton-proton running, approximately 1500 individual event selections were included in a trigger menu which specified the physics signatures and selection algorithms used for the data-taking, and the allocated event rate and bandwidth. The trigger menu must reflect the physics goals for a given data collection period, taking into account the instantaneous luminosity of the LHC and limitations from the ATLAS detector readout, online processing farm, and offline storage. This document discusses the operation of the ATLAS trigger system during the nominal proton-proton data collection in Run 2 with examples of special data-taking runs. Aspects of software validation, evolution of the trigger selection algorithms during Run 2, monitoring of the trigger system and data quality as well as trigger configuration are presented.},
author = {{The ATLAS Collaboration}},
doi = {10.1088/1748-0221/15/10/P10004},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aad et al. - 2020 - Operation of the ATLAS trigger system in Run 2.pdf:pdf},
issn = {1748-0221},
journal = {J. Instrum.},
keywords = {Data acquisition concepts,Data reduction methods,Online farms and online filtering,Trigger concepts and systems (hardware and softwar},
month = {oct},
number = {10},
pages = {P10004},
publisher = {IOP Publishing},
title = {{Operation of the ATLAS trigger system in Run 2}},
url = {https://iopscience.iop.org/article/10.1088/1748-0221/15/10/P10004 https://iopscience.iop.org/article/10.1088/1748-0221/15/10/P10004/meta},
volume = {15},
year = {2020}
}
@article{Andersson1983,
author = {Andersson, B. and Gustafson, G. and Ingelman, G. and Sj{\"{o}}strand, T.},
doi = {10.1016/0370-1573(83)90080-7},
issn = {0370-1573},
journal = {Phys. Rep.},
month = {jul},
number = {2-3},
pages = {31--145},
publisher = {North-Holland},
title = {{Parton fragmentation and string dynamics}},
volume = {97},
year = {1983}
}
@article{ATLAS2020a,
abstract = {The ATLAS detector at the Large Hadron Collider reads out particle collision data from over 100 million electronic channels at a rate of approximately 100 kHz, with a recording rate for physics events of approximately 1 kHz. Before being certified for physics analysis at computer centres worldwide, the data must be scrutinised to ensure they are clean from any hardware or software related issues that may compromise their integrity. Prompt identification of these issues permits fast action to investigate, correct and potentially prevent future such problems that could render the data unusable. This is achieved through the monitoring of detector-level quantities and reconstructed collision event characteristics at key stages of the data processing chain. This paper presents the monitoring and assessment procedures in place at ATLAS during 2015-2018 data-taking. Through the continuous improvement of operational procedures, ATLAS achieved a high data quality efficiency, with 95.6\% of the recorded proton-proton collision data collected at s=13 TeV certified for physics analysis.},
archivePrefix = {arXiv},
arxivId = {physics.ins-det/1911.04632},
author = {{The ATLAS Collaboration}},
doi = {10.1088/1748-0221/15/04/P04003},
eprint = {1911.04632},
issn = {17480221},
journal = {J. Instrum.},
keywords = {Large detector systems for particle and astroparti,Large detector-systems performance},
number = {4},
pages = {P04003},
primaryClass = {physics.ins-det},
title = {{ATLAS data quality operations and performance for 2015-2018 data-taking}},
volume = {15},
year = {2020}
}
@misc{Peskin1995,
address = {Reading, Mass.},
author = {Peskin, Michael Edward and Schroeder, Daniel V},
isbn = {0201503972},
keywords = {Feynman diagrams,Feynman diagrams; Gauge fields (Physics); Quantum,Gauge fields (Physics),Quantum},
publisher = {Addison-Wesley Pub. Co},
title = {{An Introduction to Quantum Field Theory}},
year = {1995}
}
@book{LHCVol2,
address = {Geneva},
author = {Br{\"{u}}ning, Oliver Sim and Collier, Paul and Lebrun, P and Myers, Stephen and Ostojic, Ranko and Poole, John and Proudlock, Paul},
doi = {10.5170/CERN-2004-003-V-2},
publisher = {CERN},
series = {CERN Yellow Reports: Monographs},
title = {{LHC Design Report Vol. II: The LHC infrastructure and general services}},
url = {http://cds.cern.ch/record/815187},
year = {2004}
}
@article{ElectronIDIso2019,
abstract = {Algorithms used for the reconstruction and identification of electrons in the central region of the ATLAS detector at the Large Hadron Collider (LHC) are presented in this paper; these algorithms are used in ATLAS physics analyses that involve electrons in the final state and which are based on the 2015 and 2016 proton-proton collision data produced by the LHC at $\sqrt{s}$ = 13 TeV. The performance of the electron reconstruction, identification, isolation, and charge identification algorithms is evaluated in data and in simulated samples using electrons from $Z\rightarrow ee$ and $J/\psi\rightarrow ee$ decays. Typical examples of combinations of electron reconstruction, identification, and isolation operating points used in ATLAS physics analyses are shown.},
archivePrefix = {arXiv},
arxivId = {1902.04655v2},
author = {{The ATLAS Collaboration}},
doi = {10.1140/epjc/s10052-019-7140-6},
eprint = {1902.04655v2},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The ATLAS Collaboration - 2019 - Electron reconstruction and identification in the ATLAS experiment using the 2015 and 2016 LHC proton-p.pdf:pdf},
journal = {Eur. Phys. J. C},
month = {feb},
number = {8},
publisher = {Springer New York LLC},
title = {{Electron reconstruction and identification in the ATLAS experiment using the 2015 and 2016 LHC proton-proton collision data at $\sqrt{s}$ = 13 TeV}},
url = {http://arxiv.org/abs/1902.04655 http://dx.doi.org/10.1140/epjc/s10052-019-7140-6},
volume = {79},
year = {2019}
}
@misc{Pequenao2008b,
author = {Pequenao, Joao},
keywords = {ATLAS,Computer Generated Images,Detectors,Muon Spectrometer,Outreach,Technology},
month = {mar},
title = {{Computer generated image of the ATLAS Muons subsystem}},
url = {https://cds.cern.ch/record/1095929},
year = {2008}
}
@book{LHCVol3,
address = {Geneva},
author = {Benedikt, Michael and Collier, Paul and Mertens, V and Poole, John and Schindl, Karlheinz},
doi = {10.5170/CERN-2004-003-V-3},
publisher = {CERN},
series = {CERN Yellow Reports: Monographs},
title = {{LHC Design Report Vol. III: The LHC injector chain}},
url = {http://cds.cern.ch/record/823808},
year = {2004}
}
@article{NNPDF3dot0,
abstract = {We present NNPDF3.0, the first set of parton distribution functions (PDFs) determined with a methodology validated by a closure test. NNPDF3.0 uses a global dataset including HERA-II deep-inelastic inclusive cross-sections, the combined HERA charm data, jet production from ATLAS and CMS, vector boson rapidity and transverse momentum distributions from ATLAS, CMS and LHCb, W +c data from CMS and top quark pair production total cross sections from ATLAS and CMS. Results are based on LO, NLO and NNLO QCD theory and also include electroweak corrections. To validate our methodology, we show that PDFs determined from pseudo-data generated from a known underlying law correctly reproduce the statistical distributions expected on the basis of the assumed experimental uncertainties. This closure test ensures that our methodological uncertainties are negligible in comparison to the generic theoretical and experimental uncertainties of PDF determination. This enables us to determine with confidence PDFs at different perturbative orders and using a variety of experimental datasets ranging from HERA-only up to a global set including the latest LHC results, all using precisely the same validated methodology. We explore some of the phenomenological implications of our results for the upcoming 13 TeV Run of the LHC, in particular for Higgs production cross-sections.},
archivePrefix = {arXiv},
arxivId = {1410.8849},
author = {Ball, Richard D. and Bertone, Valerio and Carrazza, Stefano and Deans, Christopher S. and {Del Debbio}, Luigi and Forte, Stefano and Guffanti, Alberto and Hartland, Nathan P. and Latorre, Jos{\'{e}} I. and Rojo, Juan and Ubiali, Maria},
doi = {10.1007/JHEP04(2015)040},
eprint = {1410.8849},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ball et al. - 2015 - Parton distributions for the LHC run II.pdf:pdf},
issn = {1029-8479},
journal = {J. High Energy Phys. 2015 20154},
keywords = {Classical and Quantum Gravitation,Elementary Particles,Quantum Field Theories,Quantum Field Theory,Quantum Physics,Relativity Theory,String Theory},
month = {apr},
number = {4},
pages = {1--148},
publisher = {Springer},
title = {{Parton distributions for the LHC run II}},
url = {https://link.springer.com/article/10.1007/JHEP04(2015)040},
volume = {2015},
year = {2015}
}
@article{Avoni2018,
abstract = {The ATLAS luminosity monitor, LUCID (LUminosity Cherenkov Integrating Detector), had to be upgraded for the second run of the LHC accelerator that started in spring 2015. The increased energy of the proton beams and the higher luminosity required a redesign of LUCID to cope with the more demanding conditions. The novelty of the LUCID-2 detector is that it uses the thin quartz windows of photomultipliers as Cherenkov medium and a small amounts of radioactive 207Bi sources deposited on to these windows to monitor the gain stability of the photomultipliers. The result is a fast and accurate luminosity determination that can be kept stable during many months of data taking. LUCID-2 can also measure the luminosity accurately online for each of the up to 2808 colliding bunch pairs in the LHC . These bunch pairs are separated by only 25 ns and new electronics has been built that can count not only the number of pulses above threshold but also integrate the pulses.},
author = {Avoni, G. and Bruschi, M. and Cabras, G. and Caforio, D. and Dehghanian, N. and Floderus, A. and Giacobbe, B. and Giannuzzi, F. and Giorgi, F. and Grafstr{\"{o}}m, P. and Hedberg, V. and Manghi, F. Lasagni and Meneghini, S. and Pinfold, J. and Richards, E. and Sbarra, C. and Cesari, N. Semprini and Sbrizzi, A. and Soluk, R. and Ucchielli, G. and Valentinetti, S. and Viazlo, O. and Villa, M. and Vittori, C. and Vuillermet, R. and Zoccoli, A.},
doi = {10.1088/1748-0221/13/07/P07017},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Avoni et al. - 2018 - The new LUCID-2 detector for luminosity measurement and monitoring in ATLAS.pdf:pdf},
issn = {1748-0221},
journal = {J. Instrum.},
keywords = {Cherenkov detectors; Photon detectors for UV,visible and IR photons (vacuum) (photomultipliers,},
month = {jul},
number = {07},
publisher = {IOP Publishing},
title = {{The new LUCID-2 detector for luminosity measurement and  monitoring  in ATLAS}},
volume = {13},
year = {2018}
}
@article{ATLAS2017densetracking,
abstract = {With the increase in energy of the Large Hadron Collider to a centre-of-mass energy of 13 TeV for Run 2, events with dense environments, such as in the cores of high-energy jets, became a focus for new physics searches as well as measurements of the Standard Model. These environments are characterized by charged-particle separations of the order of the tracking detectors sensor granularity. Basic track quantities are compared between 3.2 fb$^{-1}$ of data collected by the ATLAS experiment and simulation of proton-proton collisions producing high-transverse-momentum jets at a centre-of-mass energy of 13 TeV. The impact of charged-particle separations and multiplicities on the track reconstruction performance is discussed. The efficiency in the cores of jets with transverse momenta between 200 GeV and 1600 GeV is quantified using a novel, data-driven, method. The method uses the energy loss, dE/dx, to identify pixel clusters originating from two charged particles. Of the charged particles creating these clusters, the measured fraction that fail to be reconstructed is $0.061 \pm 0.006 \textrm{(stat.)} \pm 0.014 \textrm{(syst.)}$ and $0.093 \pm 0.017 \textrm{(stat.)}\pm 0.021 \textrm{(syst.)}$ for jet transverse momenta of 200-400 GeV and 1400-1600 GeV, respectively.},
archivePrefix = {arXiv},
arxivId = {1704.07983},
author = {{The ATLAS Collaboration}},
doi = {10.1140/epjc/s10052-017-5225-7},
eprint = {1704.07983},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ATLAS Collaboration - 2017 - Performance of the ATLAS Track Reconstruction Algorithms in Dense Environments in LHC Run 2.pdf:pdf},
journal = {Eur. Phys. J. C},
keywords = {ATLAS: performance,CERN LHC Coll,charged particle,cluster,detector,efficiency,energy loss,experimental results,jet: transverse momentum,multiplicity,new physics,p p: scattering,pixel,track data analysis,tracker,tracking detector,tracks},
month = {apr},
number = {10},
pages = {673},
publisher = {Springer New York LLC},
title = {{Performance of the ATLAS Track Reconstruction Algorithms in Dense Environments in LHC Run 2}},
url = {http://arxiv.org/abs/1704.07983 http://dx.doi.org/10.1140/epjc/s10052-017-5225-7},
volume = {77},
year = {2017}
}
@article{Smirnov1939,
author = {Smirnov, N},
journal = {Recl. Math{\'{e}}matique [ Mat. Sb. ]},
number = {48},
pages = {3--26},
title = {{Sur les {\'{e}}carts de la courbe de distribution empirique}},
volume = {6},
year = {1939}
}
@article{NNPDF3dot1,
abstract = {We present a new set of parton distributions, NNPDF3.1, which updates NNPDF3.0, the first global set of PDFs determined using a methodology validated by a closure test. The update is motivated by recent progress in methodology and available data, and involves both. On the methodological side, we now parametrize and determine the charm PDF alongside the light-quark and gluon ones, thereby increasing from seven to eight the number of independent PDFs. On the data side, we now include the D0 electron and muon W asymmetries from the final Tevatron dataset, the complete LHCb measurements of W and Z production in the forward region at 7 and 8 TeV, and new ATLAS and CMS measurements of inclusive jet and electroweak boson production. We also include for the first time top-quark pair differential distributions and the transverse momentum of the Z bosons from ATLAS and CMS. We investigate the impact of parametrizing charm and provide evidence that the accuracy and stability of the PDFs are thereby improved. We study the impact of the new data by producing a variety of determinations based on reduced datasets. We find that both improvements have a significant impact on the PDFs, with some substantial reductions in uncertainties, but with the new PDFs generally in agreement with the previous set at the one-sigma level. The most significant changes are seen in the light-quark flavor separation, and in increased precision in the determination of the gluon. We explore the implications of NNPDF3.1 for LHC phenomenology at Run II, compare with recent LHC measurements at 13 TeV, provide updated predictions for Higgs production cross-sections and discuss the strangeness and charm content of the proton in light of our improved dataset and methodology. The NNPDF3.1 PDFs are delivered for the first time both as Hessian sets, and as optimized Monte Carlo sets with a compressed number of replicas.},
author = {Ball, Richard D. and Bertone, Valerio and Carrazza, Stefano and Debbio, Luigi Del and Forte, Stefano and Groth-Merrild, Patrick and Guffanti, Alberto and Hartland, Nathan P. and Kassabov, Zahari and Latorre, Jos{\'{e}} I. and Nocera, Emanuele R. and Rojo, Juan and Rottoli, Luca and Slade, Emma and Ubiali, Maria},
doi = {10.1140/EPJC/S10052-017-5199-5},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ball et al. - 2017 - Parton distributions from high-precision collider data.pdf:pdf},
issn = {1434-6052},
journal = {Eur. Phys. J. C 2017 7710},
keywords = {Astronomy,Astrophysics and Cosmology,Elementary Particles,Hadrons,Heavy Ions,Measurement Science and Instrumentation,Nuclear Energy,Nuclear Physics,Quantum Field Theories,Quantum Field Theory,String Theory},
month = {oct},
number = {10},
pages = {1--75},
publisher = {Springer},
title = {{Parton distributions from high-precision collider data}},
url = {https://link.springer.com/article/10.1140/epjc/s10052-017-5199-5},
volume = {77},
year = {2017}
}
@article{Steerenberg2019,
abstract = {Run 2 of the CERN Large Hadron Collider (LHC) started in April 2015 and was successfully completed on 10 th December 2018, achieving largely all goals set in terms of luminosity production. Following the first two-year long shutdown and the re-commissioning in 2015 at 6.5 TeV, the beam performance was increased to reach a peak luminosity of more than twice the design value and a colliding beam time ratio of 50%. This was accomplished thanks to the increased beam brightness from the injector chain, the high machine availability and the performance enhancements made in the LHC for which some methods and tools, foreseen for the High Luminosity LHC (HL-LHC) were tested and deployed operationally. This contribution provides an overview of the operational aspects, main limitations and achievements for the proton Run 2.},
author = {Steerenberg, Rende and Alemany-Fernandez, R and {Albert Argyropoulos}, M T and Bravin, Enrico and Crockford, Guy and Dumont, J-c and {Fuchsberger Giachino}, K R and Giovannozzi, Massimo and Hemelsoet, G-h and H{\"{o}}fle, Wolfgang and Jacquet, Delphine and Lamont, Mike and M{\'{e}}tral, Elias and Nisbet, David and Papotti, Giulia and Pojer, Mirko and Ponce, Laurette and Redaelli, Stefano and Salvachua, Belen and Schaumann, Michaela and {Solfaroli Camillocci}, M and Suykerbuyk, Ronaldus and Trad, Georges and Uznanski, Slawosz and Uythoven, Jan and Walsh, David and Wenninger, Jorg and Zerlauth, Markus},
doi = {10.18429/JACoW-IPAC2019-MOPMP031},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steerenberg et al. - 2019 - Operation and performance of the CERN Large Hadron Collider during Proton Run 2.pdf:pdf},
isbn = {9783954502080},
journal = {10th Int. Part. Accel. Conf.},
keywords = {emittance,injection,luminosity,operation,proton},
number = {10},
pages = {504--507},
title = {{Operation and performance of the CERN Large Hadron Collider during proton Run 2}},
url = {http://cds.cern.ch/record/2696126},
year = {2019}
}
@article{ATLASpaper,
author = {{The ATLAS Collaboration}},
doi = {10.1088/1748-0221/3/08/S08003},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aad et al. - 2008 - The ATLAS Experiment at the CERN Large Hadron Collider.pdf:pdf},
issn = {1748-0221},
journal = {J. Instrum.},
keywords = {ATLAS,Accelerator,Accordion geometry,B-tagging,Bandwidth,Bunch-crossings,CERN,Calorimetry,Carbon-fibre reinforced plastics,Cerenkov light,Charged-particle tracking,Detector control system,Drift tubes,Electromagnetic and hadronic interactions,Electrons,Event filter,Fluorinert cooling,Forward calorimetry,Forward detectors,Hall probes,Heavy-ion collisions,High-level trigger,Impact parameter measurements,Inner detector,Jets,LHC,Lateral segmentation,Leptons,Liquid argon,Longitudinal segmentation,Magnetic field measurements,Minimum-bias events,Missing transverse energy,Muon spectrometer,Muons,Optical alignment systems,Optical fibres,Particle identification,Photons,Pile-up,Pixel detectors,Precision-tracking chambers,Processor farm,Proton-proton collisions,Radiation-hard electronics,Resistive-plate chambers,Roman Pots,Sampling calorimeters,Scintillator tiles,Silicon micro-strip detectors,Solenoidal field,Superconducting magnets,Taus,Thin-gap chambers,Time-over-threshold,Toroidal field,Tracking algorithms,Transition radiation,Trigger and data acquisition,Trigger chambers,Vertex measurement,Vertexing algorithms,Zero-degree calorimetry},
month = {aug},
number = {08},
pages = {S08003},
publisher = {IOP Publishing},
title = {{The ATLAS Experiment at the CERN Large Hadron Collider}},
url = {https://iopscience.iop.org/article/10.1088/1748-0221/3/08/S08003 https://iopscience.iop.org/article/10.1088/1748-0221/3/08/S08003/meta},
volume = {3},
year = {2008}
}
@inproceedings{Ostojic2002,
abstract = {The Large Hadron Collider comprises eight insertions, four of which are dedicated to the LHC experiments while the others are used for the major collider systems. The various functions of the insertions are fulfilled by a variety of magnet systems, most of them based on the technology of NbTi superconductors cooled by superfluid helium at 1.9 K. A number of stand-alone magnets in the matching sections are operated at 4.5 K, while in the high radiation areas specialized resistive magnets are used. In this paper, we review the concepts underlying the design of the LHC insertions, and report on the design, procurement and testing of the various specialized magnet systems.},
author = {Ostojic, R},
booktitle = {IEEE Trans. Appl. Supercond.},
doi = {10.1109/TASC.2002.1018382},
file = {:home/harry/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ostojic - 2002 - The LHC insertion magnets.pdf:pdf},
issn = {10518223},
keywords = {Insertions,LHC,Superconducting magnets},
month = {mar},
number = {1},
organization = {CERN},
pages = {196--201},
title = {{The LHC insertion magnets}},
volume = {12},
year = {2002}
}
